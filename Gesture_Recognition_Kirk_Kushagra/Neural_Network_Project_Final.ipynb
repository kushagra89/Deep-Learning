{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "def imread(path):\n",
    "    from PIL import Image\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "def imresize(img, size):\n",
    "    from PIL import Image\n",
    "    return np.array(Image.fromarray(np.uint8(img)).resize(size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size):\n",
    "    print('Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = [0,1,2,4,6,7,8,10,12,13,14,16,18,19,20,22,24,25,26,28]\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(t) // batch_size\n",
    "        for batch in range(num_batches):\n",
    "            batch_data = np.zeros((batch_size, 20, 120, 120, 3))\n",
    "            batch_labels = np.zeros((batch_size, 5))\n",
    "            for folder in range(batch_size):\n",
    "                imgs = os.listdir('Project_data/'+source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0])\n",
    "                for idx, item in enumerate(img_idx):\n",
    "                    image = imread('Project_data/'+source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    image = imresize(image,(120, 120))\n",
    "                                        \n",
    "                    batch_data[folder,idx,:,:,0] = (image[:,:, 0])/255 \n",
    "                    batch_data[folder,idx,:,:,1] = (image[:,:, 1])/255 \n",
    "                    batch_data[folder,idx,:,:,2] = (image[:,:, 2])/255\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels\n",
    "\n",
    "        if (len(t) / batch_size) != 0:\n",
    "            batch_data = np.zeros((batch_size, 20, 120, 120, 3))\n",
    "            batch_labels = np.zeros((batch_size, 5))\n",
    "            for folder in range(batch_size):\n",
    "                imgs = os.listdir('Project_data/'+source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0])\n",
    "                for idx,item in enumerate(img_idx):\n",
    "                    image = imread('Project_data/'+source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    image = imresize(image,(120, 120)).astype(np.float32)\n",
    "                    batch_data[folder,idx,:,:,0] = (image[:,:, 0])/255\n",
    "                    batch_data[folder,idx,:,:,1] = (image[:,:, 1])/255\n",
    "                    batch_data[folder,idx,:,:,2] = (image[:,:, 2])/255\n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 20\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = 'train'\n",
    "val_path = 'val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 20\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries to be used\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model #1 - Basic Conv3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Shape = (20, 120, 120, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(16, (3, 3, 3), padding='same', input_shape=(Input_Shape)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 20, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 20, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 10, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                18432032  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 18,433,701\n",
      "Trainable params: 18,433,605\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(learning_rate = 0.00001)\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'GR_Model' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = False\n",
    "                             , mode = 'auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 10, verbose = 1, mode = \"auto\", epsilon = 1e-06\n",
    "                       , cooldown = 0, min_lr = 0)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  train ; batch size = 16\n",
      "Epoch 1/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.6624 - categorical_accuracy: 0.4102Source path =  val ; batch size = 16\n",
      "42/42 [==============================] - 131s 3s/step - loss: 1.6564 - categorical_accuracy: 0.4120 - val_loss: 2.1960 - val_categorical_accuracy: 0.1875\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.19596, saving model to GR_Model_2021-11-1408_27_02.838782/model-00001-1.40520-0.49107-2.19596-0.18750.h5\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 49s 1s/step - loss: 0.7214 - categorical_accuracy: 0.7452 - val_loss: 2.2660 - val_categorical_accuracy: 0.2321\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.19596\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.4198 - categorical_accuracy: 0.9074 - val_loss: 2.2946 - val_categorical_accuracy: 0.2946\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.19596\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2587 - categorical_accuracy: 0.9562 - val_loss: 2.0656 - val_categorical_accuracy: 0.4018\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.19596 to 2.06562, saving model to GR_Model_2021-11-1408_27_02.838782/model-00004-0.25476-0.94494-2.06562-0.40179.h5\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.1637 - categorical_accuracy: 0.9938 - val_loss: 1.8307 - val_categorical_accuracy: 0.3839\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.06562 to 1.83071, saving model to GR_Model_2021-11-1408_27_02.838782/model-00005-0.15835-0.99256-1.83071-0.38393.h5\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.1113 - categorical_accuracy: 0.9980 - val_loss: 1.4895 - val_categorical_accuracy: 0.4464\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.83071 to 1.48948, saving model to GR_Model_2021-11-1408_27_02.838782/model-00006-0.11389-0.99702-1.48948-0.44643.h5\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.0880 - categorical_accuracy: 0.9991 - val_loss: 1.4763 - val_categorical_accuracy: 0.4554\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.48948 to 1.47625, saving model to GR_Model_2021-11-1408_27_02.838782/model-00007-0.07718-0.99851-1.47625-0.45536.h5\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.0673 - categorical_accuracy: 1.0000 - val_loss: 1.4041 - val_categorical_accuracy: 0.4643\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.47625 to 1.40409, saving model to GR_Model_2021-11-1408_27_02.838782/model-00008-0.06339-1.00000-1.40409-0.46429.h5\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.0536 - categorical_accuracy: 0.9997 - val_loss: 1.2880 - val_categorical_accuracy: 0.5446\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.40409 to 1.28799, saving model to GR_Model_2021-11-1408_27_02.838782/model-00009-0.05631-0.99851-1.28799-0.54464.h5\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.0539 - categorical_accuracy: 0.9976 - val_loss: 1.3171 - val_categorical_accuracy: 0.5089\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.28799\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.0486 - categorical_accuracy: 0.9993 - val_loss: 1.1738 - val_categorical_accuracy: 0.5804\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.28799 to 1.17381, saving model to GR_Model_2021-11-1408_27_02.838782/model-00011-0.05083-0.99851-1.17381-0.58036.h5\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 48s 1s/step - loss: 0.0415 - categorical_accuracy: 0.9997 - val_loss: 1.0799 - val_categorical_accuracy: 0.6429\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.17381 to 1.07989, saving model to GR_Model_2021-11-1408_27_02.838782/model-00012-0.04142-0.99851-1.07989-0.64286.h5\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.0390 - categorical_accuracy: 1.0000 - val_loss: 1.2642 - val_categorical_accuracy: 0.6071\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.07989\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.0280 - categorical_accuracy: 1.0000 - val_loss: 1.0201 - val_categorical_accuracy: 0.6696\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.07989 to 1.02010, saving model to GR_Model_2021-11-1408_27_02.838782/model-00014-0.02995-1.00000-1.02010-0.66964.h5\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.0287 - categorical_accuracy: 1.0000 - val_loss: 1.1327 - val_categorical_accuracy: 0.6607\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.02010\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.0280 - categorical_accuracy: 1.0000 - val_loss: 1.1033 - val_categorical_accuracy: 0.6518\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.02010\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.0239 - categorical_accuracy: 1.0000 - val_loss: 1.1224 - val_categorical_accuracy: 0.6964\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.02010\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.0201 - categorical_accuracy: 1.0000 - val_loss: 1.1193 - val_categorical_accuracy: 0.6786\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.02010\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.0202 - categorical_accuracy: 1.0000 - val_loss: 1.1654 - val_categorical_accuracy: 0.6518\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.02010\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.0221 - categorical_accuracy: 1.0000 - val_loss: 1.2421 - val_categorical_accuracy: 0.6339\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.02010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5488058c40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = num_epochs, verbose = 1, callbacks = callbacks_list\n",
    "          , validation_data = val_generator, validation_steps = validation_steps, class_weight = None, workers = 1\n",
    "          , initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Observation`: <b>As expected, base model is not performing well and is overfitting. Highest validation accuracy is 69.64%.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model #2 - Conv3D with Multiple Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(16, (3, 3, 3), padding = 'same', input_shape = (Input_Shape)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size = (2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(32, (3, 3, 3), padding = 'same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size = (2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(64, (3, 3, 3), padding = 'same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size = (2, 2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_10 (Conv3D)           (None, 20, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 20, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 20, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 10, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 10, 60, 60, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 10, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 5, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 5, 30, 30, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 5, 30, 30, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               3686528   \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,758,661\n",
      "Trainable params: 3,758,181\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(learning_rate = 0.00001)\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'GR_Model' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = False\n",
    "                             , mode = 'auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 4, verbose = 1, mode = \"auto\", epsilon = 1e-08\n",
    "                       , cooldown = 0, min_lr = 0)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 49s 1s/step - loss: 1.9078 - categorical_accuracy: 0.2906 - val_loss: 1.9379 - val_categorical_accuracy: 0.2679\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.93793, saving model to GR_Model_2021-11-1408_27_02.838782/model-00001-1.56632-0.41518-1.93793-0.26786.h5\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.8419 - categorical_accuracy: 0.6882 - val_loss: 2.8201 - val_categorical_accuracy: 0.1875\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.93793\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.6441 - categorical_accuracy: 0.7776 - val_loss: 3.9748 - val_categorical_accuracy: 0.2857\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.93793\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.4418 - categorical_accuracy: 0.8700 - val_loss: 4.1517 - val_categorical_accuracy: 0.2768\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.93793\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.3551 - categorical_accuracy: 0.9306 - val_loss: 4.2978 - val_categorical_accuracy: 0.2946\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.93793\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2249 - categorical_accuracy: 0.9676 - val_loss: 3.9382 - val_categorical_accuracy: 0.3214\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.93793\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2500 - categorical_accuracy: 0.9715 - val_loss: 3.4785 - val_categorical_accuracy: 0.3571\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.93793\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 48s 1s/step - loss: 0.2496 - categorical_accuracy: 0.9660 - val_loss: 3.1560 - val_categorical_accuracy: 0.3036\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.93793\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2231 - categorical_accuracy: 0.9638 - val_loss: 2.5199 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.93793\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2715 - categorical_accuracy: 0.9303 - val_loss: 2.2074 - val_categorical_accuracy: 0.4018\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.93793\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2294 - categorical_accuracy: 0.9582 - val_loss: 1.4142 - val_categorical_accuracy: 0.6071\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.93793 to 1.41417, saving model to GR_Model_2021-11-1408_27_02.838782/model-00011-0.23269-0.96875-1.41417-0.60714.h5\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2383 - categorical_accuracy: 0.9529 - val_loss: 1.4001 - val_categorical_accuracy: 0.5357\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.41417 to 1.40011, saving model to GR_Model_2021-11-1408_27_02.838782/model-00012-0.23815-0.96131-1.40011-0.53571.h5\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2341 - categorical_accuracy: 0.9775 - val_loss: 1.2867 - val_categorical_accuracy: 0.6161\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.40011 to 1.28667, saving model to GR_Model_2021-11-1408_27_02.838782/model-00013-0.22188-0.97917-1.28667-0.61607.h5\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.2357 - categorical_accuracy: 0.9712 - val_loss: 1.1285 - val_categorical_accuracy: 0.6607\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.28667 to 1.12849, saving model to GR_Model_2021-11-1408_27_02.838782/model-00014-0.22454-0.97321-1.12849-0.66071.h5\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2435 - categorical_accuracy: 0.9626 - val_loss: 1.1100 - val_categorical_accuracy: 0.6339\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.12849 to 1.11002, saving model to GR_Model_2021-11-1408_27_02.838782/model-00015-0.24263-0.96429-1.11002-0.63393.h5\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2343 - categorical_accuracy: 0.9571 - val_loss: 0.8233 - val_categorical_accuracy: 0.7946\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.11002 to 0.82330, saving model to GR_Model_2021-11-1408_27_02.838782/model-00016-0.22729-0.96429-0.82330-0.79464.h5\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2138 - categorical_accuracy: 0.9683 - val_loss: 1.2652 - val_categorical_accuracy: 0.6161\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.82330\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 48s 1s/step - loss: 0.2140 - categorical_accuracy: 0.9560 - val_loss: 1.0984 - val_categorical_accuracy: 0.6696\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.82330\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2112 - categorical_accuracy: 0.9709 - val_loss: 1.0419 - val_categorical_accuracy: 0.7054\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.82330\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.2305 - categorical_accuracy: 0.9722 - val_loss: 1.0211 - val_categorical_accuracy: 0.7232\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.82330\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f538c619220>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = num_epochs, verbose = 1, callbacks = callbacks_list\n",
    "          , validation_data = val_generator, validation_steps = validation_steps, class_weight = None, workers = 1\n",
    "          , initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Observation`: <b>Model is still overfitting. However, model performance has improved significantly. Highest validation accuracy is 79.46%. Average </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model #3 - 3D Conv with Multiple Layers and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Shape = (20, 120, 120, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(16, (3, 3, 3), padding = 'same', input_shape = (Input_Shape)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size = (2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(32, (3, 3, 3), padding = 'same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size = (2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(64, (3, 3, 3), padding = 'same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size = (2, 2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 20, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 20, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 20, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 10, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 10, 60, 60, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 5, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 5, 30, 30, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 5, 30, 30, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1843264   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 1,914,821\n",
      "Trainable params: 1,914,469\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(learning_rate = 0.00001)\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'GR_Model' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = False\n",
    "                             , mode = 'auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 4, verbose = 1, mode = \"auto\", epsilon = 1e-08\n",
    "                       , cooldown = 0, min_lr = 0)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  train ; batch size = 16\n",
      "Epoch 1/20\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.2761 - categorical_accuracy: 0.2429Source path =  val ; batch size = 16\n",
      "42/42 [==============================] - 130s 3s/step - loss: 2.2707 - categorical_accuracy: 0.2441 - val_loss: 1.6359 - val_categorical_accuracy: 0.2321\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.63586, saving model to GR_Model_2021-11-1417_26_26.760695/model-00001-2.04268-0.29167-1.63586-0.23214.h5\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 48s 1s/step - loss: 1.4801 - categorical_accuracy: 0.4418 - val_loss: 2.4935 - val_categorical_accuracy: 0.2232\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.63586\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.2179 - categorical_accuracy: 0.5103 - val_loss: 3.2763 - val_categorical_accuracy: 0.2321\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.63586\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.0602 - categorical_accuracy: 0.5975 - val_loss: 4.0575 - val_categorical_accuracy: 0.2054\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.63586\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.8749 - categorical_accuracy: 0.6372 - val_loss: 4.6792 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.63586\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.8517 - categorical_accuracy: 0.6680 - val_loss: 4.0805 - val_categorical_accuracy: 0.3125\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.63586\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.9128 - categorical_accuracy: 0.6633 - val_loss: 3.8414 - val_categorical_accuracy: 0.2589\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.63586\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.7554 - categorical_accuracy: 0.7224 - val_loss: 3.1218 - val_categorical_accuracy: 0.3036\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.63586\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.8161 - categorical_accuracy: 0.7030 - val_loss: 2.5114 - val_categorical_accuracy: 0.3393\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.63586\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.7924 - categorical_accuracy: 0.7269 - val_loss: 2.0744 - val_categorical_accuracy: 0.3661\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.63586\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.8758 - categorical_accuracy: 0.6716 - val_loss: 1.4107 - val_categorical_accuracy: 0.4554\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.63586 to 1.41074, saving model to GR_Model_2021-11-1417_26_26.760695/model-00011-0.87318-0.65476-1.41074-0.45536.h5\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.9206 - categorical_accuracy: 0.6548 - val_loss: 1.1297 - val_categorical_accuracy: 0.5446\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.41074 to 1.12972, saving model to GR_Model_2021-11-1417_26_26.760695/model-00012-0.86674-0.67113-1.12972-0.54464.h5\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.8169 - categorical_accuracy: 0.7033 - val_loss: 1.1102 - val_categorical_accuracy: 0.6339\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.12972 to 1.11020, saving model to GR_Model_2021-11-1417_26_26.760695/model-00013-0.81478-0.68155-1.11020-0.63393.h5\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.8954 - categorical_accuracy: 0.6765 - val_loss: 0.9132 - val_categorical_accuracy: 0.7054\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.11020 to 0.91323, saving model to GR_Model_2021-11-1417_26_26.760695/model-00014-0.84933-0.67708-0.91323-0.70536.h5\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.8032 - categorical_accuracy: 0.6933 - val_loss: 0.9040 - val_categorical_accuracy: 0.6607\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.91323 to 0.90405, saving model to GR_Model_2021-11-1417_26_26.760695/model-00015-0.88163-0.67857-0.90405-0.66071.h5\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.7822 - categorical_accuracy: 0.6779 - val_loss: 0.8627 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.90405 to 0.86266, saving model to GR_Model_2021-11-1417_26_26.760695/model-00016-0.82527-0.66815-0.86266-0.62500.h5\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.8636 - categorical_accuracy: 0.6410 - val_loss: 0.8880 - val_categorical_accuracy: 0.6607\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.86266\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.8139 - categorical_accuracy: 0.6656 - val_loss: 0.8784 - val_categorical_accuracy: 0.6696\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.86266\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.7889 - categorical_accuracy: 0.6798 - val_loss: 0.9471 - val_categorical_accuracy: 0.6071\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.86266\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.7847 - categorical_accuracy: 0.7112 - val_loss: 0.9415 - val_categorical_accuracy: 0.6607\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.86266\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f49e0051ca0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = num_epochs, verbose = 1, callbacks = callbacks_list\n",
    "          , validation_data = val_generator, validation_steps = validation_steps, class_weight = None, workers = 1\n",
    "          , initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Observation`: <b>With the addition of Dropout, overfitting has been addressed. Best validation accuracy for the model is 66.96%</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model #4 - 3D Conv with Less Layers as Model #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(16, (2, 2, 2), padding='same', input_shape=(Input_Shape)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_3 (Conv3D)            (None, 20, 120, 120, 16)  400       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 20, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 20, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 10, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 60, 60, 32)    4128      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 5, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 144000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4608032   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 4,613,045\n",
      "Trainable params: 4,612,885\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(learning_rate = 0.00001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'GR_Model' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = False\n",
    "                             , mode = 'auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 4, verbose = 1, mode = \"auto\", epsilon = 1e-08\n",
    "                       , cooldown = 0, min_lr = 0)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 49s 1s/step - loss: 2.0431 - categorical_accuracy: 0.3266 - val_loss: 1.7756 - val_categorical_accuracy: 0.2679\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.77559, saving model to GR_Model_2021-11-1417_26_26.760695/model-00001-1.77104-0.39137-1.77559-0.26786.h5\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 1.0595 - categorical_accuracy: 0.5923 - val_loss: 2.7188 - val_categorical_accuracy: 0.2679\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.77559\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.9012 - categorical_accuracy: 0.6598 - val_loss: 3.3108 - val_categorical_accuracy: 0.3036\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.77559\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.7109 - categorical_accuracy: 0.7094 - val_loss: 3.6509 - val_categorical_accuracy: 0.2768\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.77559\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.5877 - categorical_accuracy: 0.7881 - val_loss: 3.4238 - val_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.77559\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.4830 - categorical_accuracy: 0.8358 - val_loss: 3.3126 - val_categorical_accuracy: 0.2411\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.77559\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.4898 - categorical_accuracy: 0.8489 - val_loss: 2.8224 - val_categorical_accuracy: 0.2857\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.77559\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.4552 - categorical_accuracy: 0.8607 - val_loss: 2.3010 - val_categorical_accuracy: 0.2679\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.77559\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.4741 - categorical_accuracy: 0.8342 - val_loss: 1.8504 - val_categorical_accuracy: 0.3214\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.77559\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.4799 - categorical_accuracy: 0.8266 - val_loss: 1.5595 - val_categorical_accuracy: 0.3571\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.77559 to 1.55952, saving model to GR_Model_2021-11-1417_26_26.760695/model-00010-0.46520-0.83631-1.55952-0.35714.h5\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.4399 - categorical_accuracy: 0.8443 - val_loss: 1.4281 - val_categorical_accuracy: 0.4018\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.55952 to 1.42813, saving model to GR_Model_2021-11-1417_26_26.760695/model-00011-0.46313-0.82887-1.42813-0.40179.h5\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.4997 - categorical_accuracy: 0.8104 - val_loss: 0.9699 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.42813 to 0.96995, saving model to GR_Model_2021-11-1417_26_26.760695/model-00012-0.46670-0.83631-0.96995-0.56250.h5\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.4627 - categorical_accuracy: 0.8378 - val_loss: 1.2270 - val_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.96995\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.4556 - categorical_accuracy: 0.8529 - val_loss: 0.8881 - val_categorical_accuracy: 0.6964\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.96995 to 0.88808, saving model to GR_Model_2021-11-1417_26_26.760695/model-00014-0.47478-0.83631-0.88808-0.69643.h5\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.4105 - categorical_accuracy: 0.8827 - val_loss: 0.9379 - val_categorical_accuracy: 0.6607\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.88808\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.4956 - categorical_accuracy: 0.8439 - val_loss: 0.8890 - val_categorical_accuracy: 0.6786\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.88808\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.4587 - categorical_accuracy: 0.8327 - val_loss: 1.0015 - val_categorical_accuracy: 0.7232\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.88808\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.4888 - categorical_accuracy: 0.8417 - val_loss: 0.7956 - val_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.88808 to 0.79563, saving model to GR_Model_2021-11-1417_26_26.760695/model-00018-0.44347-0.85119-0.79563-0.68750.h5\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 0.4482 - categorical_accuracy: 0.8670 - val_loss: 0.8353 - val_categorical_accuracy: 0.7321\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.79563\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 0.4447 - categorical_accuracy: 0.8551 - val_loss: 0.9733 - val_categorical_accuracy: 0.6429\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.79563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4a746f02e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Observation`: <b>There is not much changes as compared to model #3. However, the model overfits because we have removed the layer with Dropout. Best validation accuracy is 73.21%.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model #5 - Conv2D + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Shape = (20, 120, 120, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same', activation='relu'), input_shape=Input_Shape))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(GRU(128))\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_26 (TimeDis (None, 20, 120, 120, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 20, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 20, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 20, 60, 60, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_30 (TimeDis (None, 20, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 20, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 20, 30, 30, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 20, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 20, 15, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 20, 15, 15, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 20, 15, 15, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 20, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 20, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_38 (TimeDis (None, 20, 6272)          0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               2458368   \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,573,925\n",
      "Trainable params: 2,573,445\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(learning_rate = 0.00001)\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'GR_Model' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = False\n",
    "                             , mode = 'auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 4, verbose = 1, mode = \"auto\", epsilon = 1e-08\n",
    "                       , cooldown = 0, min_lr = 0)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 60s 1s/step - loss: 1.8543 - categorical_accuracy: 0.1954 - val_loss: 1.6166 - val_categorical_accuracy: 0.1518\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.61658, saving model to GR_Model_2021-11-1408_27_02.838782/model-00001-1.76923-0.23065-1.61658-0.15179.h5\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 45s 1s/step - loss: 1.6561 - categorical_accuracy: 0.2605 - val_loss: 1.6144 - val_categorical_accuracy: 0.2143\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.61658 to 1.61441, saving model to GR_Model_2021-11-1408_27_02.838782/model-00002-1.62262-0.27976-1.61441-0.21429.h5\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.4978 - categorical_accuracy: 0.3460 - val_loss: 1.6520 - val_categorical_accuracy: 0.1964\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.61441\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 1.4231 - categorical_accuracy: 0.3961 - val_loss: 1.6721 - val_categorical_accuracy: 0.2232\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.61441\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.3642 - categorical_accuracy: 0.4602 - val_loss: 1.7430 - val_categorical_accuracy: 0.2054\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.61441\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.2582 - categorical_accuracy: 0.4916 - val_loss: 1.8516 - val_categorical_accuracy: 0.2143\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.61441\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 48s 1s/step - loss: 1.2520 - categorical_accuracy: 0.5146 - val_loss: 1.7312 - val_categorical_accuracy: 0.2589\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.61441\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.1723 - categorical_accuracy: 0.5586 - val_loss: 1.7436 - val_categorical_accuracy: 0.2232\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.61441\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 1.1992 - categorical_accuracy: 0.5467 - val_loss: 1.6819 - val_categorical_accuracy: 0.2589\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.61441\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.1814 - categorical_accuracy: 0.5767 - val_loss: 1.5682 - val_categorical_accuracy: 0.2768\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.61441 to 1.56817, saving model to GR_Model_2021-11-1408_27_02.838782/model-00010-1.18778-0.57440-1.56817-0.27679.h5\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.2055 - categorical_accuracy: 0.5224 - val_loss: 1.5186 - val_categorical_accuracy: 0.3661\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.56817 to 1.51863, saving model to GR_Model_2021-11-1408_27_02.838782/model-00011-1.19608-0.54018-1.51863-0.36607.h5\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.1532 - categorical_accuracy: 0.5673 - val_loss: 1.4691 - val_categorical_accuracy: 0.3482\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.51863 to 1.46914, saving model to GR_Model_2021-11-1408_27_02.838782/model-00012-1.15449-0.58185-1.46914-0.34821.h5\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.1610 - categorical_accuracy: 0.5673 - val_loss: 1.3304 - val_categorical_accuracy: 0.4643\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.46914 to 1.33037, saving model to GR_Model_2021-11-1408_27_02.838782/model-00013-1.15533-0.57292-1.33037-0.46429.h5\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 48s 1s/step - loss: 1.1931 - categorical_accuracy: 0.5587 - val_loss: 1.2820 - val_categorical_accuracy: 0.5089\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.33037 to 1.28201, saving model to GR_Model_2021-11-1408_27_02.838782/model-00014-1.18485-0.56101-1.28201-0.50893.h5\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 1.1596 - categorical_accuracy: 0.5799 - val_loss: 1.2335 - val_categorical_accuracy: 0.5179\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.28201 to 1.23346, saving model to GR_Model_2021-11-1408_27_02.838782/model-00015-1.13240-0.60119-1.23346-0.51786.h5\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 48s 1s/step - loss: 1.1711 - categorical_accuracy: 0.5662 - val_loss: 1.2225 - val_categorical_accuracy: 0.5179\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.23346 to 1.22254, saving model to GR_Model_2021-11-1408_27_02.838782/model-00016-1.15691-0.57738-1.22254-0.51786.h5\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 48s 1s/step - loss: 1.1485 - categorical_accuracy: 0.5722 - val_loss: 1.1982 - val_categorical_accuracy: 0.5357\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.22254 to 1.19818, saving model to GR_Model_2021-11-1408_27_02.838782/model-00017-1.12767-0.60268-1.19818-0.53571.h5\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.1519 - categorical_accuracy: 0.5716 - val_loss: 1.2068 - val_categorical_accuracy: 0.5089\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.19818\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 46s 1s/step - loss: 1.1170 - categorical_accuracy: 0.5962 - val_loss: 1.1687 - val_categorical_accuracy: 0.5446\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.19818 to 1.16868, saving model to GR_Model_2021-11-1408_27_02.838782/model-00019-1.11938-0.59077-1.16868-0.54464.h5\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 47s 1s/step - loss: 1.1036 - categorical_accuracy: 0.5919 - val_loss: 1.1538 - val_categorical_accuracy: 0.5714\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.16868 to 1.15381, saving model to GR_Model_2021-11-1408_27_02.838782/model-00020-1.12293-0.58482-1.15381-0.57143.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f53601687f0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch = steps_per_epoch, epochs = num_epochs, verbose = 1, callbacks = callbacks_list\n",
    "          , validation_data = val_generator, validation_steps = validation_steps, class_weight = None, workers = 1\n",
    "          , initial_epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Observation`: <b>Conv2D + RNN model is not performing well but has no overfitting. Best validation accuracy is 57.14%.</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
